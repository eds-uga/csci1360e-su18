{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "qbonus_prompt",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# BONUS\n",
    "\n",
    "This bonus will do a very deep dive into dictionaries and lists, and do so within the context of a real-world application.\n",
    "\n",
    "CodeNeuro is a project run out of HHMI Janelia Farms which looks at designing algorithms to automatically identify neurons in time-lapse microscope data. The competition is called \"NeuroFinder\": \n",
    "http://neurofinder.codeneuro.org/\n",
    "\n",
    "The goal of the project is to use data that look like this\n",
    "\n",
    "![unlabeled](movie-0.png)\n",
    "\n",
    "and automatically segment out all the neurons in the image, like so\n",
    "\n",
    "![labeled](zooming-0.png)\n",
    "\n",
    "As you can probably imagine, storing this information is tricky, requiring a great deal of specifics. To store this data, they use a data format we haven't covered before called JSON, or **J**ava**S**cript **O**bject **N**otation. It's an extremely flexible data storage format, using regular old text but structuring it in such a way that you can store pretty much any information you want. As a bonus, its structure maps *really really well* to **dictionaries**.\n",
    "\n",
    "In the CodeNeuro competition, then, the JSON format is used to submit predictions from participating competitors. Recalling the aforementioned goal of the competition (re: the two above images), the format of the JSON submissions is as follows:\n",
    "\n",
    " - The first layer is a **list**, where each item in the list is a **dictionary**. Each item (again, a dictionary) corresponds to a single dataset.\n",
    " - One of the dictionaries will contain two keys: `dataset`, which gives the name of the dataset as the value (a string), and `regions`, which contains a **list** of all the regions found in that dataset.\n",
    " - A single item in the list of regions is a **dictionary**, with one key: `coordinates`.\n",
    " - The value for `coordinates` is, again, a **list**, where each element of the list is an `(x, y)` pair that specifies a pixel in the region.\n",
    " \n",
    "That's a lot, for sure. Here's an example of a JSON structure representing two different datasets, where one dataset has only 1 region and the other dataset has 2 regions:\n",
    "\n",
    "```\n",
    "'[\n",
    "  {\"dataset\": \"d1\", \"regions\":\n",
    "    [\n",
    "      {\"coordinates\": [[1, 2], [3, 4], [4, 5]]}\n",
    "    ]\n",
    "  },\n",
    "  \n",
    "  {\"dataset\": \"d2\", \"regions\":\n",
    "    [\n",
    "      {\"coordinates\": [[2, 3], [4, 10]]},\n",
    "      {\"coordinates\": [[20, 20], [20, 21], [22, 23]]}\n",
    "    ]\n",
    "  }\n",
    "]'\n",
    "```\n",
    "\n",
    "You have two datasets, `d1` and `d2`, represented as two elements in the outermost list. Those two dictionaries have two keys, `dataset` (the name of the dataset) and `regions` (the list of regions outlining neurons present in that dataset). The `regions` field is a list of dictionaries, and the length of the list is how many distinct regions/neurons there are in that dataset. For example, in `d1` above, there is only 1 neuron/region, but in `d2`, there are 2 neurons/regions. Each region is just a list of `(x, y)` tuple integers that specify a pixel in the image dataset that is part of the region.\n",
    "\n",
    "*WHEW*. That's a lot. We'll try to start things off slowly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "qbonusa_prompt",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Part A\n",
    "\n",
    "Write a function which:\n",
    "\n",
    " - is named `count_datasets`\n",
    " - takes 1 argument: a string to a JSON file\n",
    " - returns 1 value: the number (integer) of datasets in the provided JSON file\n",
    "\n",
    "The JSON file string provided to the function indicates the file on the hard disk that represents a submission for CodeNeuro. Your function should go through the JSON structure in this file, count the number of datasets present in it, and return an integer count of the number of datasets present in the JSON input file.\n",
    "\n",
    "This function should read the file off the hard disk, count the number of datasets in the file, and return that number. It should also be able to handle file exceptions gracefully; if an error is encountered, return `-1` to represent this. Otherwise, the return value should always be 0 or greater.\n",
    "\n",
    "You can use the `json` Python library; otherwise, no other imports are allowed. Here is the Python JSON library documentatio: https://docs.python.org/3/library/json.html Of particular note, for *reading* JSON files, is the [`json.load` function](https://docs.python.org/3/library/json.html#json.load)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "qbonusa",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "qbonusa_test1",
     "locked": true,
     "points": 7,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "c = count_datasets(\"submission_partial.json\")\n",
    "assert c == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "qqbonusa_test2",
     "locked": true,
     "points": 7,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "c = count_datasets(\"submission_full.json\")\n",
    "assert c == 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "qbonusa_test3",
     "locked": true,
     "points": 6,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    c = count_datasets(\"submission_nonexistent.json\")\n",
    "except:\n",
    "    assert False\n",
    "else:\n",
    "    assert c == -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "qbonusb_prompt",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Part B\n",
    "\n",
    "Write a function which:\n",
    "\n",
    " - is named `get_dataset_by_index`\n",
    " - takes 2 arguments: the name of the JSON file on the filesystem (same as in Part A), and the *integer index* of the data to return from that JSON file\n",
    " - returns 1 value: the JSON dataset specified by the integer index argument\n",
    "\n",
    "This function should return the dictionary corresponding to the dataset in the JSON file, or `None` if an invalid integer index is supplied (e.g. specified 10 when there are only 4 datasets, or a negative number). It should also be able to handle file-related errors.\n",
    "\n",
    "You can use the `json` Python library; otherwise, no other imports are allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "qbonusb",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "qbonusb_test1",
     "locked": true,
     "points": 7,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "d = json.loads(open(\"partial_1.json\", \"r\").read())\n",
    "assert d == get_dataset_by_index(\"submission_partial.json\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "qbonusb_test2",
     "locked": true,
     "points": 7,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "d = json.loads(open(\"full_8.json\", \"r\").read())\n",
    "assert d == get_dataset_by_index(\"submission_full.json\", 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "qbonusb_test3",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    c = get_dataset_by_index(\"submission_partial.json\", 5)\n",
    "except:\n",
    "    assert False\n",
    "else:\n",
    "    assert c is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "qbonusb_test4",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    c = get_dataset_by_index(\"submission_nonexistent.json\", 4983)\n",
    "except:\n",
    "    assert False\n",
    "else:\n",
    "    assert c is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "qbonusc_prompt",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Part C\n",
    "\n",
    "Write a function which:\n",
    "\n",
    " - is named `get_dataset_by_name`\n",
    " - takes 2 arguments: the name of the JSON file on the filesystem (same as in Part A and B), and a string indicating the name of the dataset to return\n",
    " - returns 1 value: the JSON dataset specified by the string name argument\n",
    " \n",
    "This solution is functionally identical to `get_dataset_by_index`, except rather than retrieving a dataset by the integer index, you instead return a dataset by its *string name*.\n",
    "\n",
    "This function should return the dictionary corresponding to the dataset in the JSON file, or `None` if an invalid name is supplied. It should also be able to handle file-related errors.\n",
    "\n",
    "You can use the `json` Python library; otherwise, no other imports are allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "qbonusc",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "qbonusc_test1",
     "locked": true,
     "points": 7,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "d = json.loads(open(\"partial_1.json\", \"r\").read())\n",
    "assert d == get_dataset_by_name(\"submission_partial.json\", \"01.01.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "qbonusc_test2",
     "locked": true,
     "points": 7,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "d = json.loads(open(\"full_8.json\", \"r\").read())\n",
    "assert d == get_dataset_by_name(\"submission_full.json\", \"04.01.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "qbonusc_test3",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    c = get_dataset_by_name(\"submission_partial.json\", \"nonexistent\")\n",
    "except:\n",
    "    assert False\n",
    "else:\n",
    "    assert c is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "qbonusc_test4",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    c = get_dataset_by_name(\"submission_nonexistent.json\", \"02.00.test\")\n",
    "except:\n",
    "    assert False\n",
    "else:\n",
    "    assert c is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "qbonusd_prompt",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Part D\n",
    "\n",
    "Write a function which:\n",
    "\n",
    " - is named `count_pixels_in_dataset`\n",
    " - takes 2 arguments: the name of the JSON file on the filesystem (same as in Part A, B, and C), and the string name of the dataset to examine (same as Part C)\n",
    " - returns 1 number: the count of pixels found in *all regions* of the specified dataset\n",
    " \n",
    "Each individual pixel is a single pair of `(x, y)` numbers (that counts as 1).\n",
    "\n",
    "If any file-related errors are encountered, or an incorrect dataset name specified, the function should return `-1`.\n",
    "\n",
    "You can use the `json` Python library, **or other functions you've already written in this question**; otherwise, no other imports are allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "qbonusd",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "qbonusd_test1",
     "locked": true,
     "points": 6,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert 29476 == count_pixels_in_dataset(\"submission_full.json\", \"01.01.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "qbonusd_test2",
     "locked": true,
     "points": 6,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert 30231 == count_pixels_in_dataset(\"submission_full.json\", \"04.01.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "qbonusd_test3",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    c = count_pixels_in_dataset(\"submission_partial.json\", \"02.00.test\")\n",
    "except:\n",
    "    assert False\n",
    "else:\n",
    "    assert c == -1"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
